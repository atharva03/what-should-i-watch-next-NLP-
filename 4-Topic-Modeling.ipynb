{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
    {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling - Attempt #1 (All Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abdul</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abortion</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absence</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abuse</th>\n",
       "      <th>abusive</th>\n",
       "      <th>academia</th>\n",
       "      <th>...</th>\n",
       "      <th>yearold</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>youd</th>\n",
       "      <th>youll</th>\n",
       "      <th>young</th>\n",
       "      <th>youre</th>\n",
       "      <th>youth</th>\n",
       "      <th>youve</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>andrew</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brene</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cameron</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>celeste</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maze</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robert</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shaw</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simon</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thomas</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tom</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 2251 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         abdul  ability  able  abortion  abroad  absence  absolutely  abuse  \\\n",
       "andrew       0        0     3         0       1        0           0      0   \n",
       "brene        0        1     2         0       0        0           3      1   \n",
       "cameron      0        0     1         0       0        0           0      0   \n",
       "celeste      0        0     1         1       0        0           0      0   \n",
       "maze         1        0     0         0       0        0           0      0   \n",
       "robert       0        0     0         0       0        0           0      0   \n",
       "shaw         0        2     3         0       0        1           0      0   \n",
       "simon        0        1     3         0       0        0           0      0   \n",
       "thomas       0        0     1         0       0        0           0      0   \n",
       "tom          0        1     0         0       0        0           1      0   \n",
       "\n",
       "         abusive  academia  ...  yearold  yes  york  youd  youll  young  \\\n",
       "andrew         1         0  ...        0    2     1     0      2      0   \n",
       "brene          0         0  ...        0    0     0     0      0      1   \n",
       "cameron        0         0  ...        0    0     2     1      1      3   \n",
       "celeste        0         0  ...        0    2     0     0      1      0   \n",
       "maze           0         0  ...        0    0     0     0      0      0   \n",
       "robert         0         0  ...        0    0     0     0      0      2   \n",
       "shaw           0         1  ...        2    0     0     1      0      0   \n",
       "simon          0         0  ...        0    1     2     0      0      0   \n",
       "thomas         0         0  ...        0    0     0     0      0      1   \n",
       "tom            0         0  ...        0    0     0     0      0      0   \n",
       "\n",
       "         youre  youth  youve  zero  \n",
       "andrew       7      0      2     0  \n",
       "brene        7      0      0     0  \n",
       "cameron      2      1      2     0  \n",
       "celeste     11      0      3     0  \n",
       "maze         8      0      0     0  \n",
       "robert       4      0      0     0  \n",
       "shaw         4      0      3     0  \n",
       "simon        4      0      0     1  \n",
       "thomas       0      0      0     0  \n",
       "tom          0      0      0     0  \n",
       "\n",
       "[10 rows x 2251 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "data = pd.read_pickle('dtm_stop_ted.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import matutils, models\n",
    "import scipy.sparse\n",
    "\n",
    "# import logging\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>andrew</th>\n",
       "      <th>brene</th>\n",
       "      <th>cameron</th>\n",
       "      <th>celeste</th>\n",
       "      <th>maze</th>\n",
       "      <th>robert</th>\n",
       "      <th>shaw</th>\n",
       "      <th>simon</th>\n",
       "      <th>thomas</th>\n",
       "      <th>tom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abdul</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abortion</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abroad</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          andrew  brene  cameron  celeste  maze  robert  shaw  simon  thomas  \\\n",
       "abdul          0      0        0        0     1       0     0      0       0   \n",
       "ability        0      1        0        0     0       0     2      1       0   \n",
       "able           3      2        1        1     0       0     3      3       1   \n",
       "abortion       0      0        0        1     0       0     0      0       0   \n",
       "abroad         1      0        0        0     0       0     0      0       0   \n",
       "\n",
       "          tom  \n",
       "abdul       0  \n",
       "ability     1  \n",
       "able        0  \n",
       "abortion    0  \n",
       "abroad      0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm = data.transpose()\n",
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df --> sparse matrix --> gensim corpus\n",
    "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim also requires dictionary of the all terms and their respective location in the term-document matrix\n",
    "cv = pickle.load(open(\"cv_stop_ted.pkl\", \"rb\"))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.009*\"think\" + 0.009*\"depression\" + 0.008*\"life\" + 0.008*\"feel\" + 0.007*\"thats\" + 0.006*\"really\" + 0.006*\"work\" + 0.006*\"brain\" + 0.006*\"look\" + 0.006*\"talk\"'),\n",
       " (1,\n",
       "  '0.014*\"dont\" + 0.010*\"believe\" + 0.008*\"talk\" + 0.007*\"youre\" + 0.007*\"right\" + 0.007*\"theyre\" + 0.006*\"buy\" + 0.005*\"conversation\" + 0.005*\"listen\" + 0.005*\"great\"')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=2, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.012*\"dont\" + 0.009*\"talk\" + 0.007*\"conversation\" + 0.007*\"app\" + 0.007*\"listen\" + 0.006*\"look\" + 0.006*\"theyre\" + 0.006*\"question\" + 0.006*\"id\" + 0.006*\"model\"'),\n",
       " (1,\n",
       "  '0.015*\"depression\" + 0.011*\"life\" + 0.010*\"think\" + 0.010*\"feel\" + 0.007*\"relationship\" + 0.007*\"dont\" + 0.006*\"talk\" + 0.006*\"study\" + 0.006*\"youre\" + 0.006*\"good\"'),\n",
       " (2,\n",
       "  '0.011*\"believe\" + 0.010*\"brain\" + 0.009*\"thats\" + 0.007*\"work\" + 0.007*\"dont\" + 0.007*\"think\" + 0.006*\"buy\" + 0.005*\"world\" + 0.005*\"talk\" + 0.005*\"theyre\"')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA for num_topics = 3\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.010*\"vulnerability\" + 0.009*\"app\" + 0.009*\"thats\" + 0.009*\"think\" + 0.008*\"work\" + 0.008*\"really\" + 0.008*\"connection\" + 0.007*\"talk\" + 0.007*\"love\" + 0.006*\"research\"'),\n",
       " (1,\n",
       "  '0.012*\"life\" + 0.012*\"dont\" + 0.010*\"relationship\" + 0.010*\"study\" + 0.010*\"talk\" + 0.009*\"conversation\" + 0.008*\"good\" + 0.008*\"listen\" + 0.007*\"really\" + 0.007*\"youre\"'),\n",
       " (2,\n",
       "  '0.018*\"brain\" + 0.010*\"positive\" + 0.009*\"happiness\" + 0.007*\"school\" + 0.007*\"thats\" + 0.007*\"average\" + 0.007*\"sister\" + 0.007*\"success\" + 0.006*\"world\" + 0.006*\"change\"'),\n",
       " (3,\n",
       "  '0.012*\"depression\" + 0.011*\"think\" + 0.011*\"dont\" + 0.009*\"feel\" + 0.008*\"believe\" + 0.007*\"right\" + 0.006*\"talk\" + 0.006*\"thats\" + 0.006*\"day\" + 0.005*\"look\"')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA for num_topics = 4\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling - Attempt #2 (Nouns Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to pull out nouns \n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "def nouns(text):\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)] \n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>andrew</th>\n",
       "      <td>i felt a funeral in my brain and mourner to an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brene</th>\n",
       "      <td>so ill start with this a couple year ago an ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cameron</th>\n",
       "      <td>hi my name be cameron russell and for the last...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>celeste</th>\n",
       "      <td>all right i want to see a show of hand how man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maze</th>\n",
       "      <td>hello doha hello salaam alaikum i love come to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robert</th>\n",
       "      <td>what keep u healthy and happy a we go through ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shaw</th>\n",
       "      <td>when i be seven year old and my sister be just...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simon</th>\n",
       "      <td>how do you explain when thing dont go a we ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thomas</th>\n",
       "      <td>ive always have a fascination for computer and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tom</th>\n",
       "      <td>my name be tom and ive come here today to come...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                transcript\n",
       "andrew   i felt a funeral in my brain and mourner to an...\n",
       "brene    so ill start with this a couple year ago an ev...\n",
       "cameron  hi my name be cameron russell and for the last...\n",
       "celeste  all right i want to see a show of hand how man...\n",
       "maze     hello doha hello salaam alaikum i love come to...\n",
       "robert   what keep u healthy and happy a we go through ...\n",
       "shaw     when i be seven year old and my sister be just...\n",
       "simon    how do you explain when thing dont go a we ass...\n",
       "thomas   ive always have a fascination for computer and...\n",
       "tom      my name be tom and ive come here today to come..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the cleaned data, before the CountVectorizer step\n",
    "data_clean = pd.read_pickle('data_clean_ted.pkl')\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>andrew</th>\n",
       "      <td>i funeral brain mourner tread — till sense — s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brene</th>\n",
       "      <td>start year event planner i speak event call fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cameron</th>\n",
       "      <td>hi name russell model year tension room i dres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>celeste</th>\n",
       "      <td>i show hand someone facebook something politic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maze</th>\n",
       "      <td>hello doha hello salaam alaikum i place nation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robert</th>\n",
       "      <td>life future self time energy survey millennial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shaw</th>\n",
       "      <td>i year sister year top bunk bed year sister ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simon</th>\n",
       "      <td>thing dont others thing assumption example app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thomas</th>\n",
       "      <td>fascination computer technology i apps iphone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tom</th>\n",
       "      <td>name come today i money mouth way exchange cas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                transcript\n",
       "andrew   i funeral brain mourner tread — till sense — s...\n",
       "brene    start year event planner i speak event call fl...\n",
       "cameron  hi name russell model year tension room i dres...\n",
       "celeste  i show hand someone facebook something politic...\n",
       "maze     hello doha hello salaam alaikum i place nation...\n",
       "robert   life future self time energy survey millennial...\n",
       "shaw     i year sister year top bunk bed year sister ti...\n",
       "simon    thing dont others thing assumption example app...\n",
       "thomas   fascination computer technology i apps iphone ...\n",
       "tom      name come today i money mouth way exchange cas..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nouns = pd.DataFrame(data_clean.transcript.apply(nouns))\n",
    "data_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abdul</th>\n",
       "      <th>ability</th>\n",
       "      <th>abortion</th>\n",
       "      <th>absence</th>\n",
       "      <th>abuse</th>\n",
       "      <th>academia</th>\n",
       "      <th>acceptance</th>\n",
       "      <th>access</th>\n",
       "      <th>accord</th>\n",
       "      <th>account</th>\n",
       "      <th>...</th>\n",
       "      <th>wuhahaha</th>\n",
       "      <th>yale</th>\n",
       "      <th>yarn</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>youd</th>\n",
       "      <th>youll</th>\n",
       "      <th>youth</th>\n",
       "      <th>youve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>andrew</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brene</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cameron</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>celeste</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maze</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robert</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shaw</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simon</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thomas</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tom</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1289 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         abdul  ability  abortion  absence  abuse  academia  acceptance  \\\n",
       "andrew       0        0         0        0      0         0           0   \n",
       "brene        0        1         0        0      1         0           0   \n",
       "cameron      0        0         0        0      0         0           0   \n",
       "celeste      0        0         1        0      0         0           1   \n",
       "maze         1        0         0        0      0         0           0   \n",
       "robert       0        0         0        0      0         0           0   \n",
       "shaw         0        2         0        1      0         1           0   \n",
       "simon        0        1         0        0      0         0           1   \n",
       "thomas       0        0         0        0      0         0           0   \n",
       "tom          0        1         0        0      0         0           0   \n",
       "\n",
       "         access  accord  account  ...  wuhahaha  yale  yarn  yeah  yes  york  \\\n",
       "andrew        1       0        0  ...         0     0     1     0    0     1   \n",
       "brene         0       0        0  ...         0     1     0     0    0     0   \n",
       "cameron       0       0        0  ...         0     0     0     1    0     2   \n",
       "celeste       0       1        0  ...         0     0     0     0    1     0   \n",
       "maze          0       0        0  ...         1     0     0     1    0     0   \n",
       "robert        0       0        0  ...         0     0     0     0    0     0   \n",
       "shaw          0       0        1  ...         0     2     0     0    0     0   \n",
       "simon         1       0        0  ...         0     0     0     0    0     2   \n",
       "thomas        0       0        0  ...         0     0     0     0    0     0   \n",
       "tom           0       0        0  ...         0     0     0     2    0     0   \n",
       "\n",
       "         youd  youll  youth  youve  \n",
       "andrew      0      1      0      0  \n",
       "brene       0      0      0      0  \n",
       "cameron     1      1      1      2  \n",
       "celeste     0      0      0      3  \n",
       "maze        0      0      0      0  \n",
       "robert      0      0      0      0  \n",
       "shaw        0      0      0      3  \n",
       "simon       0      0      0      0  \n",
       "thomas      0      0      0      0  \n",
       "tom         0      0      0      0  \n",
       "\n",
       "[10 rows x 1289 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# document-term matrix using only nouns\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Re-add stop words \n",
    "add_stop_words = ['like', 'im', 'know', 'year', 'dont', 'thats', 'right', 'people',\n",
    "                  'youre', 'got', 'gonna', 'time', 'think', 'thing', 'say','way']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "\n",
    "# document-term matrix with only nouns\n",
    "cvn = CountVectorizer(stop_words=stop_words)\n",
    "data_cvn = cvn.fit_transform(data_nouns.transcript)\n",
    "data_dtmn = pd.DataFrame(data_cvn.toarray(), columns=cvn.get_feature_names())\n",
    "data_dtmn.index = data_nouns.index\n",
    "data_dtmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gensim corpus\n",
    "corpusn = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmn.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordn = dict((v, k) for k, v in cvn.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.027*\"laughter\" + 0.013*\"life\" + 0.011*\"brain\" + 0.008*\"work\" + 0.008*\"relationship\" + 0.007*\"talk\" + 0.007*\"study\" + 0.007*\"conversation\" + 0.007*\"research\" + 0.006*\"school\"'),\n",
       " (1,\n",
       "  '0.023*\"depression\" + 0.011*\"day\" + 0.009*\"laughter\" + 0.007*\"treatment\" + 0.007*\"fact\" + 0.007*\"brain\" + 0.007*\"life\" + 0.006*\"model\" + 0.006*\"world\" + 0.005*\"work\"')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=2, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.028*\"life\" + 0.025*\"laughter\" + 0.022*\"relationship\" + 0.017*\"study\" + 0.011*\"men\" + 0.010*\"friend\" + 0.008*\"family\" + 0.006*\"health\" + 0.006*\"guy\" + 0.006*\"east\"'),\n",
       " (1,\n",
       "  '0.020*\"laughter\" + 0.009*\"conversation\" + 0.009*\"talk\" + 0.009*\"work\" + 0.008*\"vulnerability\" + 0.008*\"day\" + 0.007*\"story\" + 0.007*\"research\" + 0.007*\"theyre\" + 0.007*\"connection\"'),\n",
       " (2,\n",
       "  '0.025*\"depression\" + 0.017*\"brain\" + 0.015*\"laughter\" + 0.009*\"day\" + 0.008*\"world\" + 0.008*\"school\" + 0.008*\"lot\" + 0.008*\"treatment\" + 0.007*\"experience\" + 0.007*\"happiness\"')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topics = 3\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=3, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.032*\"laughter\" + 0.026*\"brain\" + 0.012*\"happiness\" + 0.011*\"school\" + 0.010*\"sister\" + 0.010*\"success\" + 0.009*\"world\" + 0.007*\"friend\" + 0.007*\"guy\" + 0.007*\"problem\"'),\n",
       " (1,\n",
       "  '0.020*\"laughter\" + 0.012*\"conversation\" + 0.010*\"vulnerability\" + 0.010*\"work\" + 0.009*\"talk\" + 0.009*\"theyre\" + 0.009*\"connection\" + 0.008*\"research\" + 0.007*\"number\" + 0.007*\"world\"'),\n",
       " (2,\n",
       "  '0.033*\"depression\" + 0.014*\"laughter\" + 0.013*\"day\" + 0.010*\"treatment\" + 0.009*\"model\" + 0.009*\"lot\" + 0.008*\"app\" + 0.008*\"life\" + 0.008*\"question\" + 0.008*\"experience\"'),\n",
       " (3,\n",
       "  '0.031*\"life\" + 0.026*\"relationship\" + 0.020*\"study\" + 0.013*\"men\" + 0.009*\"laughter\" + 0.008*\"work\" + 0.008*\"health\" + 0.008*\"family\" + 0.008*\"loop\" + 0.007*\"id\"')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 4 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=4, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling - Attempt #3 (Nouns and Adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nouns_adj(text):\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)] \n",
    "    return ' '.join(nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>andrew</th>\n",
       "      <td>i funeral brain mourner tread — tread — till s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brene</th>\n",
       "      <td>ill start couple year event planner i speak ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cameron</th>\n",
       "      <td>hi name russell last little ive model year i u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>celeste</th>\n",
       "      <td>right i show hand many someone facebook someth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maze</th>\n",
       "      <td>hello doha hello salaam alaikum i internationa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robert</th>\n",
       "      <td>u healthy happy life future best self time ene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shaw</th>\n",
       "      <td>i year old sister year old top bunk bed i year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simon</th>\n",
       "      <td>thing dont others able thing assumption exampl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thomas</th>\n",
       "      <td>ive fascination computer technology i few apps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tom</th>\n",
       "      <td>name tom ive come today clean i money i mouth ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                transcript\n",
       "andrew   i funeral brain mourner tread — tread — till s...\n",
       "brene    ill start couple year event planner i speak ev...\n",
       "cameron  hi name russell last little ive model year i u...\n",
       "celeste  right i show hand many someone facebook someth...\n",
       "maze     hello doha hello salaam alaikum i internationa...\n",
       "robert   u healthy happy life future best self time ene...\n",
       "shaw     i year old sister year old top bunk bed i year...\n",
       "simon    thing dont others able thing assumption exampl...\n",
       "thomas   ive fascination computer technology i few apps...\n",
       "tom      name tom ive come today clean i money i mouth ..."
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nouns_adj = pd.DataFrame(data_clean.transcript.apply(nouns_adj))\n",
    "data_nouns_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abdul</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abortion</th>\n",
       "      <th>absence</th>\n",
       "      <th>abuse</th>\n",
       "      <th>abusive</th>\n",
       "      <th>academia</th>\n",
       "      <th>academic</th>\n",
       "      <th>acceptance</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yearlong</th>\n",
       "      <th>yearold</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>youd</th>\n",
       "      <th>youll</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>andrew</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brene</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cameron</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>celeste</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maze</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robert</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shaw</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simon</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thomas</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tom</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1762 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         abdul  ability  able  abortion  absence  abuse  abusive  academia  \\\n",
       "andrew       0        0     3         0        0      0        1         0   \n",
       "brene        0        1     2         0        0      1        0         0   \n",
       "cameron      0        0     1         0        0      0        0         0   \n",
       "celeste      0        0     1         1        0      0        0         0   \n",
       "maze         1        0     0         0        0      0        0         0   \n",
       "robert       0        0     0         0        0      0        0         0   \n",
       "shaw         0        2     3         0        1      0        0         1   \n",
       "simon        0        1     3         0        0      0        0         0   \n",
       "thomas       0        0     1         0        0      0        0         0   \n",
       "tom          0        1     0         0        0      0        0         0   \n",
       "\n",
       "         academic  acceptance  ...  yeah  yearlong  yearold  yes  york  youd  \\\n",
       "andrew          1           0  ...     0         0        0    0     1     0   \n",
       "brene           2           0  ...     0         1        0    0     0     0   \n",
       "cameron         0           0  ...     1         0        0    0     2     1   \n",
       "celeste         0           1  ...     0         0        0    1     0     0   \n",
       "maze            0           0  ...     1         0        0    0     0     0   \n",
       "robert          0           0  ...     0         0        0    0     0     0   \n",
       "shaw            0           0  ...     0         0        2    0     0     1   \n",
       "simon           0           1  ...     0         0        0    1     2     0   \n",
       "thomas          0           0  ...     0         0        0    0     0     0   \n",
       "tom             0           0  ...     2         0        0    0     0     0   \n",
       "\n",
       "         youll  young  youth  youve  \n",
       "andrew       1      0      0      0  \n",
       "brene        0      1      0      0  \n",
       "cameron      1      3      1      2  \n",
       "celeste      0      0      0      3  \n",
       "maze         0      0      0      0  \n",
       "robert       0      2      0      0  \n",
       "shaw         0      0      0      3  \n",
       "simon        0      0      0      0  \n",
       "thomas       0      1      0      0  \n",
       "tom          0      0      0      0  \n",
       "\n",
       "[10 rows x 1762 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# document-term matrix using only nouns and adjectives\n",
    "cvna = CountVectorizer(stop_words=stop_words, max_df=.8)\n",
    "data_cvna = cvna.fit_transform(data_nouns_adj.transcript)\n",
    "data_dtmna = pd.DataFrame(data_cvna.toarray(), columns=cvna.get_feature_names())\n",
    "data_dtmna.index = data_nouns_adj.index\n",
    "data_dtmna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gensim corpus\n",
    "corpusna = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmna.transpose()))\n",
    "\n",
    "#vocabulary dictionary\n",
    "id2wordna = dict((v, k) for k, v in cvna.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.015*\"depression\" + 0.007*\"talk\" + 0.006*\"life\" + 0.006*\"theyre\" + 0.006*\"day\" + 0.006*\"conversation\" + 0.006*\"vulnerability\" + 0.005*\"question\" + 0.005*\"research\" + 0.005*\"experience\"'),\n",
       " (1,\n",
       "  '0.012*\"brain\" + 0.009*\"life\" + 0.006*\"relationship\" + 0.006*\"world\" + 0.006*\"study\" + 0.005*\"day\" + 0.005*\"school\" + 0.005*\"success\" + 0.005*\"positive\" + 0.004*\"app\"')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=2, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.013*\"app\" + 0.010*\"middle\" + 0.009*\"lot\" + 0.008*\"program\" + 0.007*\"east\" + 0.007*\"hello\" + 0.006*\"little\" + 0.006*\"ive\" + 0.006*\"guy\" + 0.006*\"sir\"'),\n",
       " (1,\n",
       "  '0.017*\"brain\" + 0.011*\"life\" + 0.009*\"relationship\" + 0.008*\"study\" + 0.008*\"world\" + 0.007*\"success\" + 0.006*\"day\" + 0.006*\"positive\" + 0.006*\"happiness\" + 0.005*\"men\"'),\n",
       " (2,\n",
       "  '0.016*\"depression\" + 0.007*\"talk\" + 0.007*\"life\" + 0.006*\"theyre\" + 0.006*\"day\" + 0.006*\"conversation\" + 0.006*\"vulnerability\" + 0.005*\"question\" + 0.005*\"experience\" + 0.005*\"little\"')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=3, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.025*\"depression\" + 0.009*\"vulnerability\" + 0.008*\"life\" + 0.008*\"treatment\" + 0.007*\"connection\" + 0.007*\"experience\" + 0.006*\"day\" + 0.006*\"research\" + 0.005*\"theyre\" + 0.005*\"story\"'),\n",
       " (1,\n",
       "  '0.020*\"brain\" + 0.011*\"positive\" + 0.010*\"happiness\" + 0.008*\"sister\" + 0.008*\"school\" + 0.008*\"average\" + 0.007*\"middle\" + 0.007*\"success\" + 0.007*\"world\" + 0.006*\"negative\"'),\n",
       " (2,\n",
       "  '0.011*\"loop\" + 0.008*\"great\" + 0.008*\"id\" + 0.008*\"applause\" + 0.008*\"lady\" + 0.008*\"music\" + 0.008*\"gentleman\" + 0.007*\"sound\" + 0.007*\"brisbane\" + 0.007*\"voice\"'),\n",
       " (3,\n",
       "  '0.012*\"life\" + 0.008*\"relationship\" + 0.008*\"day\" + 0.008*\"theyre\" + 0.007*\"conversation\" + 0.007*\"study\" + 0.006*\"talk\" + 0.006*\"question\" + 0.006*\"app\" + 0.006*\"number\"')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Topics in Each Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.025*\"depression\" + 0.017*\"life\" + 0.012*\"relationship\" + 0.009*\"study\" + 0.008*\"day\" + 0.008*\"treatment\" + 0.006*\"experience\" + 0.005*\"bad\" + 0.005*\"men\" + 0.005*\"medication\"'),\n",
       " (1,\n",
       "  '0.011*\"vulnerability\" + 0.008*\"connection\" + 0.007*\"research\" + 0.006*\"middle\" + 0.006*\"shame\" + 0.006*\"lady\" + 0.006*\"story\" + 0.006*\"applause\" + 0.006*\"life\" + 0.005*\"theyre\"'),\n",
       " (2,\n",
       "  '0.013*\"brain\" + 0.007*\"world\" + 0.007*\"day\" + 0.006*\"conversation\" + 0.006*\"school\" + 0.006*\"success\" + 0.006*\"question\" + 0.006*\"talk\" + 0.006*\"theyre\" + 0.005*\"positive\"')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final LDA\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=3, id2word=id2wordna, passes=100)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "four topics \n",
    "* Topic 0: life, relation\n",
    "* Topic 1: research\n",
    "* Topic 2: conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'andrew'),\n",
       " (1, 'brene'),\n",
       " (2, 'cameron'),\n",
       " (2, 'celeste'),\n",
       " (1, 'maze'),\n",
       " (0, 'robert'),\n",
       " (2, 'shaw'),\n",
       " (2, 'simon'),\n",
       " (2, 'thomas'),\n",
       " (1, 'tom')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topics each transcript contains\n",
    "corpus_transformed = ldana[corpusna]\n",
    "list(zip([a for [(a,b)] in corpus_transformed], data_dtmna.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "  first pass of LDA\n",
    "* Topic 0: life, relation [andrew,maze,robert]\n",
    "* Topic 1: research [brene,simon]\n",
    "* Topic 2: conversation [cameron,celeste,shaw,thomas,tom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
